{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646655d9-fc48-4396-9a1b-59c770e5b53f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x0000022AABA45210>>\n",
      "Traceback (most recent call last):\n",
      "  File \"E:\\Felpipe\\Proyectos propios\\GNNs-Challenges\\venv\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 781, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59f961-201f-41bf-a247-e1a9284128f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edges_df = pd.read_csv('musae_git_edges.csv')\n",
    "#features_df = pd.read_json('musae_git_features.json')\n",
    "with open('musae_git_features.json', 'r', encoding='utf-8') as data:\n",
    "    features_raw = json.load(data)\n",
    "target_df = pd.read_csv('musae_git_target.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31232d5e-11f8-4a37-be10-1e4da7477a25",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7dec2-a689-4cc4-9f14-3cec37d68a05",
   "metadata": {},
   "source": [
    "## Descripción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7b592c-fa90-4610-af29-13f02ee5a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1d137-a745-4fe0-9bee-bdcdacbe631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_raw['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958372d7-6e86-41a8-8ca1-b47e2060b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a191bfe-7b11-4a3d-bf16-3d362eb30fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_edges_from([(1, 2), (2, 3), (3, 1)])\n",
    "G.add_edges_from([(2, 4), (4, 3)])\n",
    "plt.axis('off')\n",
    "nx.draw_networkx(G,node_size=600,font_color='white')\n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9971a52-12a6-4d2c-af25-e6dd396b44b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(\n",
    "    edges_df,\n",
    "    source='id_1',\n",
    "    target='id_2',\n",
    "    create_using=nx.Graph()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba173ffc-f682-4358-83d6-17fc36706fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.set_node_attributes(G, features_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c274e-bbd7-4824-8fb4-7d7f4d18ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz de adyacencia\n",
    "A_sparse = nx.adjacency_matrix(G)\n",
    "#A = A_sparse.toarray() #Versión densa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815c69b7-28d7-4c9b-8257-ddc4a83f9373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz de grado\n",
    "from scipy.sparse import diags\n",
    "nodelist = list(G.nodes())\n",
    "deg = [G.degree(n) for n in nodelist]\n",
    "D_sparse = diags(deg, offsets=0, format=\"csr\")\n",
    "# D = np.diag(deg) ##Versión densa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81f021-55ca-4182-83f8-e8f876c94cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz Laplaciana\n",
    "L_sparse = nx.laplacian_matrix(G, nodelist=nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4421639c-d73a-485b-a041-9ce094372007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resumen del grafo\n",
    "N = G.number_of_nodes()\n",
    "M = G.number_of_edges()\n",
    "density = nx.density(G)\n",
    "trans = nx.transitivity(G)\n",
    "print('G = (V,E)')\n",
    "print(f'Tamaño |V| = {N} nodos')\n",
    "print(f'Tamaño |E| = {M} aristas')\n",
    "print(f'Densidad: {density:.4f}')\n",
    "print(f'Transitividad: {trans:.4f}')\n",
    "degrees = np.array([d for _, d in G.degree()])\n",
    "print(f'Mínimo grado: {degrees.min()}')\n",
    "print(f'Máximo grado: {degrees.max()}')\n",
    "print(f'Grado promedio: {degrees.mean():.2f}')\n",
    "print(f'Número de componentes conexas: {nx.number_connected_components(G)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc4a0ef-d3db-4916-9fc0-b440815ab9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_cc = max(nx.connected_components(G), key=len)\n",
    "G_lcc = G.subgraph(largest_cc)\n",
    "clustering_global = nx.transitivity(G) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c691e6e4-1381-4a33-9421-1b51d448e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Diámetro: {nx.diameter(G_lcc)}')\n",
    "print(f'Radio: {nx.radius(G_lcc)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde9a79-09fe-4da1-a72c-6748a36e2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Media del camino más corto: {nx.average_shortest_path_length(G_lcc)}')\n",
    "print(f'Euleriano: {nx.is_eulerian(G)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2de653-3ef2-41d0-af99-aace5b03c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Grado centralidad: {nx.degree_centrality(G)}')\n",
    "print(f'Cercanía centralidad: {nx.is_eulerian(G)}')\n",
    "print(f'Entremedio del centro: {nx.betweenness_centrality(G)}')\n",
    "print(f'Centralidad de los vectores propios: {nx.eigenvector_centrality(G)}')\n",
    "print(f'Pagerank: {nx.pagerank(G)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26b8c70-b285-4789-8851-ddc6d4483ff7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 6. Densidad y transitividad\n",
    "density     = nx.density(G)\n",
    "transitivity = nx.transitivity(G)\n",
    "\n",
    "# 7. Propiedades espectrales\n",
    "A = nx.adjacency_matrix(G)\n",
    "# – Radio espectral (mayor valor absoluto de A)\n",
    "spectral_radius = eigsh(A, k=1, which='LM', return_eigenvectors=False)[0]\n",
    "\n",
    "# – Algebraic connectivity (segundo menor autovalor de la Laplaciana)\n",
    "L = nx.laplacian_matrix(G)\n",
    "eigvals_L = eigsh(L, k=2, which='SM', return_eigenvectors=False)\n",
    "fiedler_value = eigvals_L[1]\n",
    "\n",
    "# – Multiplicidad del autovalor cero en L\n",
    "zero_mult = sum(abs(eigvals_L) < 1e-6)\n",
    "\n",
    "# – Bipartito (comprobación espectral más sencilla via función directa)\n",
    "is_bipartite = nx.is_bipartite(G)\n",
    "\n",
    "# – Número de caminatas cerradas de longitud 3 (triángulos × 6)\n",
    "closed_walks_3 = (A ** 3).diagonal().sum().item()\n",
    "\n",
    "# --- Mostrar resultados ---\n",
    "print(f\"Nodos: {num_nodes}, Aristas: {num_edges}\")\n",
    "print(f\"Grado medio: {avg_degree:.2f}\")\n",
    "print(f\"Componentes conexas: {num_cc}\")\n",
    "print(f\"Diámetro (LCC): {diameter}, Radio (LCC): {radius}\")\n",
    "print(f\"Clustering global: {clustering_global:.4f}\")\n",
    "print(f\"Camino medio (LCC): {avg_shortest_path:.4f}\")\n",
    "print(f\"Euleriano: {is_eulerian}\")\n",
    "print(f\"Densidad: {density:.6f}, Transitividad: {transitivity:.4f}\")\n",
    "print(f\"Radio espectral: {spectral_radius:.4f}\")\n",
    "print(f\"Conectividad algebraica (Fiedler): {fiedler_value:.4f}\")\n",
    "print(f\"Multiplicidad de 0 en L: {zero_mult}\")\n",
    "print(f\"Bipartito: {is_bipartite}\")\n",
    "print(f\"Caminatas cerradas de longitud 3: {closed_walks_3:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab017c-69af-4929-97ce-8f0629e05060",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.axis('off')\n",
    "nx.draw_networkx(G,node_size=600,font_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab6871-5fe1-45bb-be9c-f34502a2f783",
   "metadata": {},
   "source": [
    "## Análisis de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af2cc16-84d5-4798-b5e4-3787372a6168",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_counts = target_df['ml_target'].value_counts(normalize=True)\n",
    "print(f'Balance de clases: {label_counts}')\n",
    "plt.bar(['Web', 'ML'], [label_counts[0].item(), label_counts[1].item()])\n",
    "plt.title('Label balances for class')\n",
    "plt.xlabel('Labels')\n",
    "plt.ylabel('Percentaje')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d65a58a-790b-46fd-94f2-dcf6bb40164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "lengths = []\n",
    "counter = Counter()\n",
    "\n",
    "for node, feat in features_raw.items():\n",
    "    lengths.append(len(feat))\n",
    "    counter.update(feat)\n",
    "\n",
    "plt.hist(lengths, bins=30)\n",
    "plt.title(\"Longitud del vector de features por nodo\")\n",
    "plt.xlabel(\"Número de tokens\") \n",
    "plt.ylabel(\"Nodos\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Longitud media:\", sum(lengths)/len(lengths))\n",
    "print(\"Vocabulario total (tokens únicos):\", len(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deeccbe-e030-410c-a871-91c83bd61f52",
   "metadata": {},
   "source": [
    "## Features vs etiqueta objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0b16e7-f486-4a0c-b9c1-b48c521c0419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'node': list(map(int, features_raw.keys())),\n",
    "    'feat_len': lengths\n",
    "}).merge(target_df, how='left', left_on='node', right_on='id')\n",
    "\n",
    "sns.boxplot(x='ml_target', y='feat_len', data=df)\n",
    "plt.title(\"Longitud de features por clase\")\n",
    "plt.xlabel(\"Clase (0=Web,1=ML)\"); plt.ylabel(\"Longitud vector\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e6d5d2-eaaf-412c-b0b9-9a9c943e2662",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23467493-74c3-4233-83df-3d365d69a8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n",
    "!pip install -q torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cad828-3eed-4efa-9ed0-232e8531c1d6",
   "metadata": {},
   "source": [
    "# Modelamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab30537-3238-4645-807d-6436b84bf803",
   "metadata": {},
   "source": [
    "Este dataset no tiene mucha explicación, pero se nota algún tipo de bolsa de palabras en los números enteros (¿repositorios populares?, etc). Se pueden utilizar técnicas de NLP como word2vec para codificar esas palabras, o bien nn.Embeddings de pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017cf512-4bed-47f2-b984-5fb185ec546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87533992-1abb-4bd8-9135-e174fa59142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817978e-7131-46f9-bb82-7f485f84910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = torch.tensor(edges_df[['id_1','id_2']].values.T, dtype=torch.long)\n",
    "mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "feat_list = [features_raw[str(i)] for i in range(N)]\n",
    "X_sparse = mlb.fit_transform(feat_list)\n",
    "y = torch.tensor(target_df.sort_values('id')['ml_target'].values, dtype=torch.long)\n",
    "data = Data(x=torch.tensor(X_sparse.toarray(), dtype=torch.float),\n",
    "            edge_index=edges, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f178d9a7-7f02-4516-ae72-2b96f930ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feat_list: lista de listas de enteros (tus tokens por nodo)\n",
    "feat_list = [features_raw[str(i)] for i in range(N)]\n",
    "\n",
    "# 1) aplanamos todas las listas en un solo vector\n",
    "flat_tokens = [tok for sub in feat_list for tok in sub]\n",
    "\n",
    "# 2) calculamos los offsets (punteros) donde empieza cada sublista\n",
    "offsets = [0]\n",
    "for sub in feat_list[:-1]:\n",
    "    offsets.append(offsets[-1] + len(sub))\n",
    "\n",
    "# 3) convertimos a tensores\n",
    "data.token_ids  = torch.tensor(flat_tokens, dtype=torch.long)\n",
    "data.token_ptrs = torch.tensor(offsets,    dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04783f0b-98c2-425d-a441-79b22b1f4d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return torch.sum(y_pred == y_true) / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cfb289-6c00-4a86-b3e5-0e2620f388ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, emb_dim, hidden_channels, out_channels,\n",
    "                 vocab_size=4005):\n",
    "        super().__init__()\n",
    "        # 1) Capa de embedding “bag of tokens”\n",
    "        self.embedding = torch.nn.EmbeddingBag(\n",
    "            num_embeddings=vocab_size,\n",
    "            embedding_dim=emb_dim,\n",
    "            mode='mean',\n",
    "            sparse=False\n",
    "        )\n",
    "        # 2) Convoluciones GCN\n",
    "        self.conv1 = GCNConv(emb_dim, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.embedding(data.token_ids, data.token_ptrs)\n",
    "        x = self.conv1(x, data.edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, data.edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs, epoch_review=20):\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                     lr=0.01,\n",
    "                                     weight_decay=5e-4)\n",
    "        self.train()\n",
    "        for epoch in range(1, epochs+1):\n",
    "            optimizer.zero_grad()\n",
    "            out = self(data)\n",
    "            loss = criterion(out[data.train_mask],\n",
    "                             data.y[data.train_mask])\n",
    "            acc  = accuracy(out[data.train_mask].argmax(dim=1),\n",
    "                            data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if epoch % epoch_review == 0:\n",
    "                self.eval()\n",
    "                out = self(data)\n",
    "                val_loss = criterion(out[data.val_mask],\n",
    "                                     data.y[data.val_mask])\n",
    "                val_acc  = accuracy(out[data.val_mask].argmax(dim=1),\n",
    "                                    data.y[data.val_mask])\n",
    "                print(f\"Epoch {epoch:>3} | \"\n",
    "                      f\"Train Loss: {loss:.3f} | Train Acc: {acc*100:>5.2f}% | \"\n",
    "                      f\"Val Loss: {val_loss:.3f} | Val Acc: {val_acc*100:>5.2f}%\")\n",
    "                self.train()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data)\n",
    "        acc = accuracy(out.argmax(dim=1)[data.test_mask],\n",
    "                       data.y[data.test_mask])\n",
    "        return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a81d313-6c9d-4501-942b-ecd352478a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn = GCN(N, 16, 2)\n",
    "gcn.fit(data, epochs=1, epoch_review=1)\n",
    "acc = gcn.test(data)\n",
    "print(f'\\nGCN test accuracy: {acc*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5ab6b05-d300-4197-a1bd-428e7d49624f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for key, value in datos.items():\n",
    "    all_words += value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36cc3ca3-2be5-471d-893f-1aa6ba24b23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "690374\n",
      "[   0    1    2 ... 4002 4003 4004]\n",
      "4005\n"
     ]
    }
   ],
   "source": [
    "print(len(all_words))\n",
    "print(np.unique(all_words))\n",
    "print(len(np.unique(all_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2eb5c349-787c-4782-90e4-9bbeada70886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d3793eb-c620-4b41-aba7-4ff8ebf8e3df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37700"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a04ee3ce-ea19-44d4-81d1-94f893a2988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289003"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bf769c-dd07-4e8d-b28e-25d6b16d645f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
